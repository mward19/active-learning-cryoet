import torch
from torch.utils.data import Dataset
import numpy as np
from tqdm.auto import tqdm
import pandas as pd

import json
import os
import re

class SubtomogramPointDataset(Dataset):
    """
    Loads subtomograms and any associated points as generated by
    dataset_creation.py.

    If return_class is on, __getitem__ returns the class index (0 if no points, 1 if points) as a tensor. If return_class is off, returns the list
    of points in the tile.
    """
    def __init__(self, base_dir, tiles_dir_name='tiling-5', return_class=True, max_tiles=None, tomo_ids=None):
        self.base_dir = base_dir
        self.return_class = return_class

        self.tomo_ids = tomo_ids

        self.tiles_dir_name = tiles_dir_name

        self.tomo_dir_regex = re.compile(r'^tomo-(\d+)$')
        self.tile_dir_regex = re.compile(r'^tile-(\d+)-(\d+)-(\d+)$')
        self.points_regex = re.compile(r'^points\.json$')

        # TODO: add augmentations

        # Get all subtomogram paths
        self.samples = []
        self.positive_indices = []
        self.negative_indices = []

        dir_list = list(os.scandir(base_dir))

        tile_idx = 0
        for tomo in tqdm(dir_list, desc='Parsing directories'):
            if not tomo.is_dir():
                continue
            match = self.tomo_dir_regex.fullmatch(tomo.name)
            if not self.tomo_dir_regex.fullmatch(tomo.name):
                continue
            tomo_id = int(match.group(1))
            if self.tomo_ids is not None and tomo_id not in self.tomo_ids:
                continue

            tiles_root = os.path.join(tomo.path, self.tiles_dir_name)
            if not os.path.isdir(tiles_root):
                continue

            tiles_list = list(os.scandir(tiles_root))
            for tile in tqdm(tiles_list, desc='Collecting tiles', leave=False):
                if not tile.is_dir():
                    continue
                if not self.tile_dir_regex.fullmatch(tile.name):
                    continue

                root = tile.path
                tile_file = os.path.join(root, "tile.npy")

                pts_file = None
                for f in os.scandir(root):
                    if f.is_file() and self.points_regex.fullmatch(f.name):
                        pts_file = f.path
                        break

                if pts_file:
                    self.positive_indices.append(tile_idx)
                    with open(pts_file) as fp:
                        raw = json.load(fp)
                        points = [tuple(p) for p in raw]
                else:
                    self.negative_indices.append(tile_idx)
                    points = []

                self.samples.append((tile_file, points))
                tile_idx += 1
                if max_tiles is not None and tile_idx > max_tiles:
                    return


    def __len__(self):
        return len(self.samples)
    
    def num_positive_samples(self):
        return len(self.positive_indices)
    def num_negative_samples(self):
        return len(self.negative_indices)
    
    def get_positive_sample(self, idx):
        return self.__getitem__(self.positive_indices[idx])
    def get_negative_sample(self, idx):
        return self.__getitem__(self.negative_indices[idx])
        
    def __getitem__(self, idx):
        tile_file, points = self.samples[idx]
        tile = np.load(tile_file).astype(np.float32)  # ensure float32
        tile = torch.from_numpy(tile).unsqueeze(0)    # convert to tensor and add singleton channel dim

        if self.return_class:
            has_point = len(points) > 0
            label = torch.tensor(has_point, dtype=torch.long)
        else:
            label = torch.tensor(points, dtype=torch.float32)

        return tile, label

def get_train_dataset_ids():
    train_dataset_info = pd.read_csv('data_info/train_datasets.csv')
    return train_dataset_info['Dataset ID'].astype(int).to_list()

def get_val_dataset_ids():
    val_dataset_info = pd.read_csv('data_info/val_datasets.csv')
    return val_dataset_info['Dataset ID'].astype(int).to_list()

def get_train_val_dataset_ids():
    return get_train_dataset_ids(), get_val_dataset_ids()

def test_viz():
    """Debugging."""
    def clip_percentile(arr):
        lo, hi = np.percentile(arr, [2, 98])
        return np.clip(arr, lo, hi)
    spd = SubtomogramPointDataset(r'/home/mward19/nobackup/autodelete/fm-data-2', return_class=False, max_tiles=1000)
    from matplotlib import pyplot as plt
    for idx in tqdm(range(spd.num_positive_samples()), total=spd.num_positive_samples()):
        tile, points = spd.get_positive_sample(idx)
        path = spd.samples[spd.positive_indices[idx]][0]
        try:
            plt.figure()
            plt.imshow(clip_percentile(tile[points[0][0]]), cmap='gray')
            plt.title('\n'.join([path[i:i+40] for i in range(0, len(path), 40)]))
            plt.scatter(points[0][2], points[0][1], c='red')
            plt.savefig(f'temp/positive-{idx}.png')
            plt.close()
        except:
            tqdm.write(f'Index {idx} is bad: see {path}')

def test_probs():
    """Debugging."""
    spd = SubtomogramPointDataset(r'/home/mward19/nobackup/autodelete/fm-data-2', return_class=True, max_tiles=1000, tomo_ids={10000, 10001})
    tile, probs = spd.get_positive_sample(0)
    print(probs)
    tile, probs = spd.get_negative_sample(0)
    print(probs)
    
if __name__ == '__main__':
    test_probs()